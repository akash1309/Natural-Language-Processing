{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic Modelling.ipynb",
      "provenance": [],
      "mount_file_id": "1mo4F4vtyw-nNqsSmFI1J1cc2vfEoPOuf",
      "authorship_tag": "ABX9TyNKcc/HSXU6JVQ2qlNl+B44"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmdrFT7Y8Jbd",
        "colab_type": "text"
      },
      "source": [
        "# <h1><b><CENTER>Latent Dirichlet Allocation(LDA)\n",
        "\n",
        "Here, We will be giving several topics and our model will predict which documents corresponds to which topic."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3fs1X987z4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHYNM1yZ8cuO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3726b96f-d054-41eb-dad8-99fbe3114af1"
      },
      "source": [
        "npr = pd.read_csv('drive/My Drive/Pytorch_DataSet/TextFiles/npr.csv')\n",
        "npr.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In the Washington of 2016, even when the polic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From photography, illustration and video, to d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Article\n",
              "0  In the Washington of 2016, even when the polic...\n",
              "1    Donald Trump has used Twitter  —   his prefe...\n",
              "2    Donald Trump is unabashedly praising Russian...\n",
              "3  Updated at 2:50 p. m. ET, Russian President Vl...\n",
              "4  From photography, illustration and video, to d..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR8QGnZ18o67",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30d043e7-6f16-4b52-b22b-593871df48fb"
      },
      "source": [
        "len(npr)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11992"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbYiYVcDKasT",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gohUTRYKj4e",
        "colab_type": "text"
      },
      "source": [
        "## First, we will perform countVectorizeration.\n",
        "\n",
        "https://towardsdatascience.com/hacking-scikit-learns-vectorizers-9ef26a7170af"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQ-mUVcR8xfb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "81278920-a3df-4241-9ed3-082c05c320a5"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
        "\"\"\"\n",
        "max_df signifies that the most frequent useless words like stop_words if they appear in 95% documents,then drop them.\n",
        "min_df signifies that a word is to be taken into consideration if it appears in atleast 2 documents.\n",
        "stop_words are to not taken into consideration.\n",
        "\"\"\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nmax_df signifies that the most frequent useless words like stop_words if they appear in 95% documents,then drop them.\\nmin_df signifies that a word is to be taken into consideration if it appears in atleast 2 documents.\\nstop_words are to not taken into consideration.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PvLmeoJLrEp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d670a2d6-a74d-4d78-898b-85189df70d5a"
      },
      "source": [
        "dtm = cv.fit_transform(npr['Article'])\n",
        "dtm"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<11992x54777 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 3033388 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYSMCvArMzRM",
        "colab_type": "text"
      },
      "source": [
        "## Now, we will perform LDA.\n",
        "\n",
        "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-latent-dirichlet-allocation-437c81220158"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4-9jv08L049",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "LDA = LatentDirichletAllocation(n_components = 7, random_state = 42)  \n",
        "#n_components refers to the number of topics u want."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQEDZ0A-NKPP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "df6aa046-2883-4fd6-df98-4eebffd986eb"
      },
      "source": [
        "LDA.fit(dtm)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
              "                          evaluate_every=-1, learning_decay=0.7,\n",
              "                          learning_method='batch', learning_offset=10.0,\n",
              "                          max_doc_update_iter=100, max_iter=10,\n",
              "                          mean_change_tol=0.001, n_components=7, n_jobs=None,\n",
              "                          perp_tol=0.1, random_state=42, topic_word_prior=None,\n",
              "                          total_samples=1000000.0, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoQvaFo0NNVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}